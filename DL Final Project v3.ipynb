{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXK9HEutb2Nq",
        "outputId": "11f2cdea-5eef-4982-fb93-1a595cd9903a"
      },
      "outputs": [],
      "source": [
        "# !pip install yolov5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !git clone https://github.com/ultralytics/yolov5.git\n",
        "# !pip install -r yolov5/requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQdle6ECbu-5"
      },
      "outputs": [],
      "source": [
        "# Include all packages\n",
        "import os\n",
        "import cv2\n",
        "from time import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from yolov5.models.yolo import Model\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggf594ltbu-6",
        "outputId": "16a72363-b0bf-4ff6-ea4d-7a639215ca4e"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# import zipfile\n",
        "# with zipfile.ZipFile('/content/drive/MyDrive/DL/FinalProject/signDatabasePublicFramesOnly.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall('./DataSet')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def ResizeImage(image: np.ndarray, x1: int, y1: int, x2: int, y2: int, newWidth: int, newHeight: int) -> tuple:\n",
        "    originalHeight, originalWidth = image.shape[:2]\n",
        "    widthScale = newWidth / originalWidth\n",
        "    heightScale = newHeight / originalHeight\n",
        "    resizedImage = cv2.resize(\n",
        "        image, (newWidth, newHeight), interpolation=cv2.INTER_LINEAR)\n",
        "    x1New, y1New = int(x1 * widthScale), int(y1 * heightScale)\n",
        "    x2New, y2New = int(x2 * widthScale), int(y2 * heightScale)\n",
        "    return resizedImage, x1New, y1New, x2New, y2New\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iMxCddibu-7"
      },
      "outputs": [],
      "source": [
        "def LoadDataSet(dataSetFolderPath: str) -> tuple:\n",
        "    images = []\n",
        "    annotations = []\n",
        "    annotationsFilePath = dataSetFolderPath+\"/allAnnotations.csv\"\n",
        "    annotationsDataFrame = pd.read_csv(annotationsFilePath, sep=\";\")\n",
        "    uniqueSigns = annotationsDataFrame['Annotation tag'].unique().tolist()\n",
        "    for index, row in annotationsDataFrame[1:].iterrows():\n",
        "        image = cv2.imread(dataSetFolderPath+\"/\"+row[0])\n",
        "        images.append(image)\n",
        "        annotations.append(\n",
        "            [uniqueSigns.index(row[1]), row[2], row[3], row[4], row[5]])\n",
        "\n",
        "    del annotationsDataFrame\n",
        "\n",
        "    return images, annotations, len(uniqueSigns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def PreProcessDataSet(images: list, annotations: list, batchSize: int, resize: tuple) -> tuple:\n",
        "    resizedImages = []\n",
        "    newAnnotations = []\n",
        "    for i, image in enumerate(images):\n",
        "        [label, x1, y1, x2, y2] = annotations[i]\n",
        "        resizedImage, x1New, y1New, x2New, y2New = ResizeImage(\n",
        "            image, x1, y1, x2, y2, resize[0], resize[1])\n",
        "        resizedImages.append(resizedImage)\n",
        "        newAnnotations.append(\n",
        "            [(i % batchSize), label, x1New, y1New, x2New, y2New])\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        resizedImages, newAnnotations, test_size=0.3, random_state=42)\n",
        "\n",
        "    return X_train, X_val, y_train, y_val\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68sCzcEAbu-7"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, transform=None):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        inputData, label = self.data[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            inputData = self.transform(inputData)\n",
        "        inputData = torch.from_numpy(inputData).float()\n",
        "        label = torch.tensor(label).float()\n",
        "        return inputData, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def CreateDataLoaders(X_train, X_val, y_train, y_val, batchSize):\n",
        "    trainDataSet = []\n",
        "    valDataSet = []\n",
        "    for i in range(len(X_train)):\n",
        "        trainDataSet.append((X_train[i], y_train[i]))\n",
        "\n",
        "    for i in range(len(X_val)):\n",
        "        valDataSet.append((X_val[i], y_val[i]))\n",
        "\n",
        "    trainDataSet = CustomDataset(trainDataSet)\n",
        "    valDataSet = CustomDataset(valDataSet)\n",
        "    trainDataLoader = DataLoader(\n",
        "        trainDataSet, batchSize=batchSize, shuffle=True, num_workers=4)\n",
        "    valDataLoader = DataLoader(\n",
        "        valDataSet, batchSize=batchSize, shuffle=False, num_workers=4)\n",
        "\n",
        "    return trainDataLoader, valDataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owhzzQF61a0L"
      },
      "outputs": [],
      "source": [
        "def TargetstoTensors(targets, batchSize, numAnchors, gridSizes, numClasses):\n",
        "    targetObject = []\n",
        "    targetClass = []\n",
        "    targetBox = []\n",
        "    for grid_size in gridSizes:\n",
        "        targetObject.append(torch.zeros(\n",
        "            (batchSize, numAnchors, grid_size, grid_size, 1)))\n",
        "        targetClass.append(torch.zeros(\n",
        "            (batchSize, numAnchors, grid_size, grid_size, numClasses)))\n",
        "        targetBox.append(torch.zeros(\n",
        "            (batchSize, numAnchors, grid_size, grid_size, 4)))\n",
        "\n",
        "    for target in targets:\n",
        "        batch_index, cls, x_center, y_center, width, height = target.long()\n",
        "\n",
        "        for i, grid_size in enumerate(gridSizes):\n",
        "\n",
        "            x_cell, y_cell = int(\n",
        "                x_center * grid_size), int(y_center * grid_size)\n",
        "            anchor = 0\n",
        "            try:\n",
        "                targetObject[i][batch_index, anchor, y_cell, x_cell, 0] = 1\n",
        "                targetClass[i][batch_index, anchor, y_cell, x_cell, cls] = 1\n",
        "                targetBox[i][batch_index, anchor, y_cell, x_cell] = torch.tensor(\n",
        "                    [x_center, y_center, width, height])\n",
        "            except Exception as e:\n",
        "                # print(e)\n",
        "                pass\n",
        "    return targetObject, targetClass, targetBox\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCXFHrH5zfQx"
      },
      "outputs": [],
      "source": [
        "class YOLOv5Loss(nn.Module):\n",
        "    def __init__(self, numClasses, numAnchors=3):\n",
        "        super(YOLOv5Loss, self).__init__()\n",
        "        self.numClasses = numClasses\n",
        "        self.numAnchors = numAnchors\n",
        "\n",
        "    def forward(self, preds, targets):\n",
        "        objectLoss = torch.tensor(0.0, device=preds[0].device)\n",
        "        classLoss = torch.tensor(0.0, device=preds[0].device)\n",
        "        boxLoss = torch.tensor(0.0, device=preds[0].device)\n",
        "        batchSize = preds[0].size(0)\n",
        "        gridSizes = [pred.size(2) for pred in preds]\n",
        "        targetObjectList, targetClassList, targetBoxList = TargetstoTensors(\n",
        "            targets, batchSize, self.numAnchors, gridSizes, self.numClasses)\n",
        "        for i, pred in enumerate(preds):\n",
        "            # pred_obj = pred[..., 4].sigmoid()\n",
        "            # pred_cls = pred[..., 5:].sigmoid()\n",
        "            # pred_box = pred[..., :4]\n",
        "\n",
        "            targetObject = targetObjectList[i].to(pred.device)\n",
        "            targetClass = targetClassList[i].to(pred.device)\n",
        "            targetBox = targetBoxList[i].to(pred.device)\n",
        "\n",
        "            objectLoss += nn.BCEWithLogitsLoss()(pred[..., 4:5], targetObject)\n",
        "            classLoss += nn.BCEWithLogitsLoss()(pred[..., 5:], targetClass)\n",
        "            boxLoss += nn.MSELoss()(pred[..., :4], targetBox)\n",
        "\n",
        "        totalLoss = objectLoss + classLoss + boxLoss\n",
        "        return totalLoss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZJ8-pMgbu-9"
      },
      "outputs": [],
      "source": [
        "def CreateYolov5Model(numClasses: int, version=\"s\"):\n",
        "    congfigFile = \"yolov5/models/yolov5{}.yaml\".format(version)\n",
        "    model = Model(congfigFile, ch=3, nc=numClasses)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ValidateEpoch(model, dataLoader, optimizer, lossFunction, device):\n",
        "    totalLoss = 0\n",
        "    model.eval()\n",
        "    dataLoaderLen = len(dataLoader)\n",
        "    \n",
        "    for i, (inputs, targets )in enumerate(dataLoader):\n",
        "        inputs = inputs.permute(0, 3, 1, 2)\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        with torch.set_grad_enabled(False):\n",
        "            outputs = model(inputs)\n",
        "            loss = lossFunction(outputs, targets)\n",
        "            \n",
        "        totalLoss += loss.item() * inputs.size(0)\n",
        "        if(((i*100)//dataLoaderLen) % 10 == 0):\n",
        "            print((i*100//dataLoaderLen), end=\"%,\")\n",
        "    print()\n",
        "    epochLoss = totalLoss / dataLoaderLen\n",
        "    return epochLoss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def TrainEpoch(model, dataLoader, optimizer, lossFunction, device):\n",
        "    totalLoss = 0\n",
        "    model.train()\n",
        "    dataLoaderLen = len(dataLoader)\n",
        "    for i, (inputs, targets )in enumerate(dataLoader):\n",
        "        inputs = inputs.permute(0, 3, 1, 2)\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        with torch.set_grad_enabled(True):\n",
        "            outputs = model(inputs)\n",
        "            loss = lossFunction(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        totalLoss += loss.item() * inputs.size(0)\n",
        "        if(((i*100)//dataLoaderLen) % 10 == 0):\n",
        "            print((i*100//dataLoaderLen), end=\"%,\")\n",
        "    print()\n",
        "    epochLoss = totalLoss / dataLoaderLen\n",
        "    return epochLoss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def TrainModel(model, dataLoader, epochs, optimizer, lossFunction, device):\n",
        "    for epoch in range(epochs):\n",
        "        print(\"Epoch {}/{}:\".format(epoch+1, epochs))\n",
        "        startTime = time()\n",
        "        print(\"Train Epoch:\")\n",
        "        TrainingEpochLoss = TrainEpoch(model, dataLoader, optimizer, lossFunction, device)\n",
        "        # print(\"Validate Epoch:\")\n",
        "        # ValidateingEpochLoss = ValidateEpoch(model, dataLoader, optimizer, lossFunction, device)\n",
        "        endTime = time()\n",
        "        timeTaken = endTime-startTime\n",
        "        print(\"Training Loss: {:.4f}\".format(TrainingEpochLoss))\n",
        "        # print(\"Validateing Loss: {:.4f}\".format(ValidateingEpochLoss))\n",
        "        print(\"Time taken: {}min, {}, secs\".format(timeTaken//60, timeTaken % 60))\n",
        "\n",
        "    print(\"Training complete.\")\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batchSize = 32\n",
        "inputShape = (416, 416)\n",
        "epochs = 100\n",
        "numAnchors = 3\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Using {} device\".format(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z884-9l6bu--"
      },
      "outputs": [],
      "source": [
        "images, annotations, numClasses = LoadDataSet(\"./DataSet\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = PreProcessDataSet(\n",
        "    images, annotations, batchSize, inputShape)\n",
        "del images\n",
        "del annotations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainDataLoader, valDataLoader = CreateDataLoaders(\n",
        "    X_train, X_val, y_train, y_val, batchSize)\n",
        "del X_train\n",
        "del y_train\n",
        "del X_val\n",
        "del y_val\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJrRAHOrbu--",
        "outputId": "fa44891a-4e64-4d4a-e5f7-6ee520ddf390"
      },
      "outputs": [],
      "source": [
        "yolov5Model = CreateYolov5Model(numClasses)\n",
        "optimizer = optim.Adam(yolov5Model.parameters(), lr=0.001)\n",
        "yolov5LossFunction= YOLOv5Loss(numClasses=numClasses)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainedModel = TrainModel(yolov5Model, trainDataLoader, epochs, optimizer, yolov5LossFunction, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(yolov5Model.state_dict(), 'Trained Model/trained_yolov5Modelv3.pth')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
