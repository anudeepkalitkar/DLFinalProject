{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXK9HEutb2Nq",
        "outputId": "8ff877a4-31a4-4368-94ef-801654377d45"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install yolov5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQdle6ECbu-5"
      },
      "outputs": [],
      "source": [
        "# Include all packages\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow.keras.layers import add, concatenate, BatchNormalization, LeakyReLU, ZeroPadding2D\n",
        "from tensorflow.keras.losses import BinaryCrossentropy, MeanSquaredError\n",
        "from tensorflow.keras.metrics import MeanIoU\n",
        "import torch.optim as optim\n",
        "\n",
        "import pandas as pd\n",
        "from yolov5.models.yolo import Model\n",
        "# from yolov5.models.common import CSPDarknet53\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2paW5x1rcBV2",
        "outputId": "02e52bb8-fcb7-48c2-fdad-6016909e9529"
      },
      "outputs": [],
      "source": [
        "!git clone https: // github.com/ultralytics/yolov5.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbxYFmu8cCA6",
        "outputId": "a8ee203c-2c88-488e-d961-fe2471dd5219"
      },
      "outputs": [],
      "source": [
        "!pip install - r yolov5/requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggf594ltbu-6",
        "outputId": "cfd70234-4c3b-46de-a8c7-95f163372952"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXAvhuVnbu-6"
      },
      "outputs": [],
      "source": [
        "#  import zipfile\n",
        "# with zipfile.ZipFile('/content/drive/MyDrive/DL/FinalProject/signDatabasePublicFramesOnly.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall('./DataSet')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OW8Sq5-Rbu-7",
        "outputId": "b1ab6c21-0c40-41d9-9387-5f8629a5a855"
      },
      "outputs": [],
      "source": [
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "print(physical_devices)\n",
        "if len(physical_devices) > 0:  # If you have at least one \"configured\" GPU, let's use it; otherwise, pass\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "    print(\"Using GPU\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iMxCddibu-7"
      },
      "outputs": [],
      "source": [
        "def LoadDataSet(dataSetFolderPath: str):\n",
        "    images = []\n",
        "    newAnnotations = []\n",
        "    annotationsFilePath = dataSetFolderPath+\"/allAnnotations.csv\"\n",
        "    annotationsDataFrame = pd.read_csv(annotationsFilePath, sep=\";\")\n",
        "    width, height = 416, 416\n",
        "    for index, row in annotationsDataFrame[1:].iterrows():\n",
        "        image = cv2.imread(dataSetFolderPath+\"/\"+row[0])\n",
        "        # cv2.imshow(\"image\", image)\n",
        "        resizedImage = cv2.resize(\n",
        "            image, (width, height), interpolation=cv2.INTER_AREA)\n",
        "        # cv2.imshow(\"resized_img\", resized_img)\n",
        "        images.append(resizedImage)\n",
        "        x1, y1, x2, y2 = row[2], row[3], row[4], row[5]\n",
        "        x1, y1 = x1 / image.shape[1], y1 / image.shape[0]\n",
        "        x2, y2 = x2 / image.shape[1], y2 / image.shape[0]\n",
        "        newAnnotations.append([x1, y1, x2, y2])\n",
        "    uniqueSigns = annotationsDataFrame['Annotation tag'].unique()\n",
        "    del annotationsDataFrame\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        images, newAnnotations, test_size=0.3, random_state=42)\n",
        "\n",
        "    return X_train, X_val, y_train, y_val, uniqueSigns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68sCzcEAbu-7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, transform=None):\n",
        "        self.data = data  # data should be a list of (input, label) pairs\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_data, label = self.data[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            input_data = self.transform(input_data)\n",
        "        input_data = torch.from_numpy(input_data).float()\n",
        "\n",
        "        return input_data, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owhzzQF61a0L"
      },
      "outputs": [],
      "source": [
        "def targets_to_tensors(targets, num_anchors, grid_sizes, num_classes):\n",
        "    batch_size = int(targets[:, 0].max()) + 1\n",
        "    target_obj = []\n",
        "    target_cls = []\n",
        "    target_box = []\n",
        "\n",
        "    for grid_size in grid_sizes:\n",
        "        target_obj.append(torch.zeros(\n",
        "            (batch_size, num_anchors, grid_size, grid_size)))\n",
        "        target_cls.append(torch.zeros(\n",
        "            (batch_size, num_anchors, grid_size, grid_size, num_classes)))\n",
        "        target_box.append(torch.zeros(\n",
        "            (batch_size, num_anchors, grid_size, grid_size, 4)))\n",
        "\n",
        "    for target in targets:\n",
        "        batch_index, cls, x_center, y_center, width, height = target.long()\n",
        "\n",
        "        for i, grid_size in enumerate(grid_sizes):\n",
        "            x_cell, y_cell = int(\n",
        "                x_center * grid_size), int(y_center * grid_size)\n",
        "            anchor = 0  # Assuming only one anchor per grid cell for simplicity\n",
        "\n",
        "            target_obj[i][batch_index, anchor, y_cell, x_cell] = 1\n",
        "            target_cls[i][batch_index, anchor, y_cell, x_cell, cls] = 1\n",
        "            target_box[i][batch_index, anchor, y_cell, x_cell] = torch.tensor(\n",
        "                [x_center, y_center, width, height])\n",
        "\n",
        "    return target_obj, target_cls, target_box\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCXFHrH5zfQx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class YOLOv5Loss(nn.Module):\n",
        "    def __init__(self, num_classes, num_anchors=3):\n",
        "        super(YOLOv5Loss, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.num_anchors = num_anchors\n",
        "\n",
        "    def forward(self, preds, targets):\n",
        "        obj_loss = torch.tensor(0.0, device=preds[0].device)\n",
        "        cls_loss = torch.tensor(0.0, device=preds[0].device)\n",
        "        box_loss = torch.tensor(0.0, device=preds[0].device)\n",
        "\n",
        "        grid_sizes = [pred.size(2) for pred in preds]\n",
        "        target_obj_list, target_cls_list, target_box_list = targets_to_tensors(\n",
        "            targets, self.num_anchors, grid_sizes, self.num_classes)\n",
        "\n",
        "        for i, pred in enumerate(preds):\n",
        "            pred_obj = pred[..., 4].sigmoid()\n",
        "            pred_cls = pred[..., 5:].sigmoid()\n",
        "            pred_box = pred[..., :4]\n",
        "\n",
        "            target_obj = target_obj_list[i].to(pred.device)\n",
        "            target_cls = target_cls_list[i].to(pred.device)\n",
        "            target_box = target_box_list[i].to(pred.device)\n",
        "\n",
        "            obj_loss += nn.BCEWithLogitsLoss()(pred[..., 4], target_obj)\n",
        "            cls_loss += nn.BCEWithLogitsLoss()(pred[..., 5:], target_cls)\n",
        "            box_loss += nn.MSELoss()(pred_box, target_box)\n",
        "\n",
        "        total_loss = obj_loss + cls_loss + box_loss\n",
        "        return total_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wInmTyvrbu-9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "def setup_yolov5_loss_and_metric(num_classes, num_anchors):\n",
        "    # Define the loss components\n",
        "    objectness_loss = nn.BCELoss()\n",
        "    class_loss = nn.BCELoss()\n",
        "    bbox_loss = nn.MSELoss()\n",
        "    mean_iou = MeanIoU(num_classes=num_classes)\n",
        "\n",
        "    def yolov5_loss(y_true, y_pred):\n",
        "        # Extract the ground truth and predictions for objectness, class, and bbox\n",
        "        y_true_objectness, y_true_class, y_true_bbox = torch.split(\n",
        "            y_true, [num_anchors, num_classes, 4], dim=-1)\n",
        "        y_pred_objectness, y_pred_class, y_pred_bbox = torch.split(\n",
        "            y_pred, [num_anchors, num_classes, 4], dim=-1)\n",
        "\n",
        "        # Calculate the individual losses\n",
        "        objectness_loss_value = objectness_loss(\n",
        "            y_pred_objectness, y_true_objectness)\n",
        "        class_loss_value = class_loss(y_pred_class, y_true_class)\n",
        "        bbox_loss_value = bbox_loss(y_pred_bbox, y_true_bbox)\n",
        "\n",
        "        # Combine the losses\n",
        "        total_loss = objectness_loss_value + class_loss_value + bbox_loss_value\n",
        "        return total_loss\n",
        "\n",
        "    return yolov5_loss, mean_iou\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZJ8-pMgbu-9"
      },
      "outputs": [],
      "source": [
        "def _create_yolov5(input_shape, num_classes, version=\"s\"):\n",
        "    cfg = f\"yolov5/models/yolov5{version}.yaml\"\n",
        "    model = Model(cfg, ch=3, nc=num_classes)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z884-9l6bu--"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val, uniqueSigns = LoadDataSet(\"./DataSet\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-JllmrYktgE",
        "outputId": "53de7ce0-b079-440b-f339-476ab43c2d56"
      },
      "outputs": [],
      "source": [
        "trainDataSet = []  # List of (input, label) pairs for the training set\n",
        "valDataSet = []  # List of (input, label) pairs for the validation set\n",
        "for i in range(len(X_train)):\n",
        "    trainDataSet.append((X_train[i], y_train[i]))\n",
        "\n",
        "for i in range(len(X_val)):\n",
        "    valDataSet.append((X_val[i], y_val[i]))\n",
        "# Create the datasets\n",
        "trainDataSetset = CustomDataset(trainDataSet)\n",
        "valDataSetset = CustomDataset(valDataSet)\n",
        "\n",
        "# Create the data loaders\n",
        "trainDataSetloader = DataLoader(\n",
        "    trainDataSetset, batch_size=32, shuffle=True, num_workers=4)\n",
        "valDataSetloader = DataLoader(\n",
        "    valDataSetset, batch_size=32, shuffle=False, num_workers=4)\n",
        "input_shape = (416, 416, 3)\n",
        "num_classes = len(uniqueSigns)\n",
        "print(num_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJrRAHOrbu--",
        "outputId": "34bebc6d-bf9c-4b27-d6e9-ceb5bec2e7b2"
      },
      "outputs": [],
      "source": [
        "yolov5_model = _create_yolov5(input_shape, num_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLRIKiDjbu--"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(yolov5_model.parameters(), lr=0.001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDLJ5fHybu--"
      },
      "outputs": [],
      "source": [
        "num_anchors = 3\n",
        "# yolov5_loss, mean_iou = setup_yolov5_loss_and_metric( num_classes, num_anchors)\n",
        "yolov5_loss = YOLOv5Loss(num_classes=num_classes)\n",
        "\n",
        "mean_iou = MeanIoU(num_classes=num_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaOqEToJbu-_",
        "outputId": "6370eea5-01d8-4fdf-f7ab-d5b4a3aaf1b5"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "num_epochs = 100\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "yolov5_model = yolov5_model.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    print('-' * 10)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for phase in ['train']:\n",
        "        if phase == 'train':\n",
        "            yolov5_model.train()  # Set model to training mode\n",
        "            data_loader = trainDataSetloader\n",
        "        else:\n",
        "            yolov5_model.eval()  # Set model to evaluate mode\n",
        "            data_loader = valDataSetloader\n",
        "        data_loaderLength = len(data_loader)\n",
        "        running_loss = 0.0\n",
        "        running_metric = 0.0\n",
        "\n",
        "        # Iterate over data.\n",
        "        for inputs, labels in data_loader:\n",
        "            inputs = inputs.permute(0, 3, 1, 2)\n",
        "            inputs = inputs.to(device)\n",
        "            labels = [torch.tensor(label).to(device) for label in labels]\n",
        "\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                outputs = yolov5_model(inputs)\n",
        "                # print(\"Outputs shapes:\")\n",
        "                # for output in outputs:\n",
        "                #     print(output.shape)\n",
        "                # print(\"Labels shapes:\")\n",
        "                # for label in labels:\n",
        "                #     print(label.shape)\n",
        "                loss = yolov5_loss(outputs, labels)\n",
        "                # metric_value = mean_iou(outputs, labels)\n",
        "\n",
        "                # Backward + optimize only if in training phase\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            # running_metric += metric_value.item() * inputs.size(0)\n",
        "\n",
        "        epoch_loss = running_loss / data_loaderLength\n",
        "        # epoch_metric = running_metric / len(data_loader.dataset)\n",
        "\n",
        "        print(f\"{phase} Loss: {epoch_loss:.4f}\")\n",
        "        print(f\"{phase} took {(time.time() - start_time):.1f} seconds\")\n",
        "\n",
        "    print()\n",
        "\n",
        "print(\"Training complete.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
