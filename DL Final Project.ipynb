{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Include all packages\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.layers import add, concatenate, BatchNormalization, LeakyReLU, ZeroPadding2D\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, MeanSquaredError\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "if len(physical_devices) > 0:  # If you have at least one \"configured\" GPU, let's use it; otherwise, pass\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    print(\"Using GPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadDataSet(dataSetFolderPath: str):\n",
    "    images = []\n",
    "    newAnnotations = []\n",
    "    annotationsFilePath = dataSetFolderPath+\"/allAnnotations.csv\"\n",
    "    annotationsDataFrame = pd.read_csv(annotationsFilePath,sep=\";\")\n",
    "    width, height = 416, 416\n",
    "    for index, row in annotationsDataFrame[1:].iterrows():\n",
    "        image = cv2.imread(dataSetFolderPath+\"/\"+row[0])\n",
    "        # cv2.imshow(\"image\", image)\n",
    "        resizedImage  = cv2.resize(image, (width, height), interpolation=cv2.INTER_AREA)\n",
    "        # cv2.imshow(\"resized_img\", resized_img)\n",
    "        images.append(resizedImage)\n",
    "        x1,y1,x2,y2 = row[2],row[3],row[4],row[5]\n",
    "        x1, y1 = x1 / image.shape[1], y1 / image.shape[0]\n",
    "        x2, y2 = x2 / image.shape[1], y2 / image.shape[0]\n",
    "        newAnnotations.append([row[1], x1,y1,x2,y2])\n",
    "    uniqueSigns =  annotationsDataFrame['Annotation tag'].unique()\n",
    "    del annotationsDataFrame\n",
    "    X_train, X_val, y_train, y_val = train_test_split(images, newAnnotations, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Create TensorFlow Datasets\n",
    "    trainDataSet = tf.data.Dataset.from_tensor_slices((np.array(X_train), np.array(y_train)))\n",
    "    valDataSet = tf.data.Dataset.from_tensor_slices((np.array(X_val), np.array(y_val)))\n",
    "    return trainDataSet, valDataSet, uniqueSigns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _conv_block(x, num_filters, kernel_size, strides=1):\n",
    "    x = Conv2D(num_filters, kernel_size, strides=strides, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _residual_block(x, num_filters):\n",
    "    shortcut = x\n",
    "    x = _conv_block(x, num_filters // 2, 1)\n",
    "    x = _conv_block(x, num_filters, 3)\n",
    "    x = add([shortcut, x])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_darknet53(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = _conv_block(inputs, 32, 3)\n",
    "    x = _conv_block(x, 64, 3, strides=2)\n",
    "\n",
    "    for _ in range(1):\n",
    "        x = _residual_block(x, 64)\n",
    "\n",
    "    x = _conv_block(x, 128, 3, strides=2)\n",
    "\n",
    "    for _ in range(2):\n",
    "        x = _residual_block(x, 128)\n",
    "\n",
    "    x = _conv_block(x, 256, 3, strides=2)\n",
    "\n",
    "    for _ in range(8):\n",
    "        x = _residual_block(x, 256)\n",
    "\n",
    "    route1 = x\n",
    "    x = _conv_block(x, 512, 3, strides=2)\n",
    "\n",
    "    for _ in range(8):\n",
    "        x = _residual_block(x, 512)\n",
    "\n",
    "    route2 = x\n",
    "    x = _conv_block(x, 1024, 3, strides=2)\n",
    "\n",
    "    for _ in range(4):\n",
    "        x = _residual_block(x, 1024)\n",
    "\n",
    "    return Model(inputs, (route1, route2, x), name='darknet53')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _create_yolov3(input_shape, num_classes):\n",
    "    darknet = _create_darknet53(input_shape[:-1] + (3,))\n",
    "\n",
    "    x = darknet.output[2]\n",
    "    x = _conv_block(x, 512, 1)\n",
    "    x = _conv_block(x, 1024, 3)\n",
    "    x = _conv_block(x, 512, 1)\n",
    "    x = _conv_block(x, 1024, 3)\n",
    "    x = _conv_block(x, 512, 1)\n",
    "\n",
    "    y1 = _conv_block(x, 1024, 3)\n",
    "    y1 = Conv2D(3 * (num_classes + 5), 1, padding='same')(y1)\n",
    "\n",
    "    x = _conv_block(x, 256, 1)\n",
    "    x = UpSampling2D(2)(x)\n",
    "    x = concatenate([x, darknet.output[1]])\n",
    "\n",
    "    x = _conv_block(x, 256, 1)\n",
    "    x = _conv_block(x, 512, 3)\n",
    "    x = _conv_block(x, 256, 1)\n",
    "    x = _conv_block(x, 512, 3)\n",
    "    x = _conv_block(x, 256, 1)\n",
    "\n",
    "    y2 = _conv_block(x, 512, 3)\n",
    "    y2 = Conv2D(3 * (num_classes + 5), 1, padding='same')(y2)\n",
    "\n",
    "    x = _conv_block(x, 128, 1)\n",
    "    x = UpSampling2D(2)(x)\n",
    "    x = concatenate([x, darknet.output[0]])\n",
    "\n",
    "    x = _conv_block(x, 128, 1)\n",
    "    x = _conv_block(x, 256, 3)\n",
    "    x = _conv_block(x, 128, 1)\n",
    "    x = _conv_block(x, 256, 3)\n",
    "    x = _conv_block(x, 128, 1)\n",
    "\n",
    "    y3 = _conv_block(x, 256, 3)\n",
    "    y3 = Conv2D(3 * (num_classes + 5), 1, padding='same')(y3)\n",
    "\n",
    "    return Model(darknet.input, (y1, y2, y3), name='yolov3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_yolov3_loss_and_metric(yolov3_model, num_classes):\n",
    "    # num_classes = 3  # Update this value according to the number of traffic sign classes in your dataset\n",
    "    num_anchors = 3  # The number of anchor boxes used in YOLOv3 (e.g., 3 for tiny YOLOv3)\n",
    "\n",
    "    # Define the loss components\n",
    "    objectness_loss = BinaryCrossentropy()\n",
    "    class_loss = BinaryCrossentropy()\n",
    "    bbox_loss = MeanSquaredError()\n",
    "\n",
    "    # Define the metric for evaluation (mean Intersection over Union)\n",
    "    mean_iou = MeanIoU(num_classes=num_classes)\n",
    "\n",
    "    def yolov3_loss(y_true, y_pred):\n",
    "        # Extract the ground truth and predictions for objectness, class, and bbox\n",
    "        y_true_objectness, y_true_class, y_true_bbox = tf.split(y_true, [num_anchors, num_classes, 4], axis=-1)\n",
    "        y_pred_objectness, y_pred_class, y_pred_bbox = tf.split(y_pred, [num_anchors, num_classes, 4], axis=-1)\n",
    "\n",
    "        # Calculate the individual losses\n",
    "        objectness_loss_value = objectness_loss(y_true_objectness, y_pred_objectness)\n",
    "        class_loss_value = class_loss(y_true_class, y_pred_class)\n",
    "        bbox_loss_value = bbox_loss(y_true_bbox, y_pred_bbox)\n",
    "\n",
    "        # Combine the losses\n",
    "        total_loss = objectness_loss_value + class_loss_value + bbox_loss_value\n",
    "        return total_loss\n",
    "\n",
    "    return yolov3_loss, mean_iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_yolov3_model(yolov3_model, trainDataSet, valDataSet, loss_function, metric):\n",
    "    # Set up the loss and metric\n",
    "\n",
    "    # Compile the model with the loss function and metric\n",
    "    yolov3_model.compile(optimizer='adam', loss=loss_function, metrics=[metric])\n",
    "\n",
    "    # Train the model on the dataset\n",
    "    history = yolov3_model.fit(\n",
    "        trainDataSet.batch(32),\n",
    "        epochs=100,\n",
    "        validation_data=valDataSet.batch(32),\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.ModelCheckpoint('yolov3_best_weights.h5', save_best_only=True, monitor='val_loss'),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, min_lr=1e-6),\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataSet, valDataSet, uniqueSigns = LoadDataSet(\"./DataSet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_shape = (416, 416, 3)\n",
    "num_classes = len(uniqueSigns)  \n",
    "\n",
    "# Create the YOLOv3 model\n",
    "yolov3_model = _create_yolov3(input_shape, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolov3_loss, mean_iou = setup_yolov3_loss_and_metric(yolov3_model, num_classes)\n",
    "# yolov3_model.compile(optimizer='adam', loss=yolov3_loss, metrics=[mean_iou])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trained_model \u001b[39m=\u001b[39m train_yolov3_model(yolov3_model, X_train, y_train, yolov3_loss, mean_iou)\n",
      "Cell \u001b[1;32mIn[21], line 8\u001b[0m, in \u001b[0;36mtrain_yolov3_model\u001b[1;34m(yolov3_model, X_train, y_train, loss_function, metric)\u001b[0m\n\u001b[0;32m      5\u001b[0m yolov3_model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39mloss_function, metrics\u001b[39m=\u001b[39m[metric])\n\u001b[0;32m      7\u001b[0m \u001b[39m# Train the model on the dataset\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m history \u001b[39m=\u001b[39m yolov3_model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      9\u001b[0m     X_train,\n\u001b[0;32m     10\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[0;32m     11\u001b[0m     validation_data\u001b[39m=\u001b[39;49my_train,\n\u001b[0;32m     12\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[\n\u001b[0;32m     13\u001b[0m         tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mModelCheckpoint(\u001b[39m'\u001b[39;49m\u001b[39myolov3_best_weights.h5\u001b[39;49m\u001b[39m'\u001b[39;49m, save_best_only\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, monitor\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mval_loss\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[0;32m     14\u001b[0m         tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mReduceLROnPlateau(monitor\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mval_loss\u001b[39;49m\u001b[39m'\u001b[39;49m, factor\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m, patience\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, min_lr\u001b[39m=\u001b[39;49m\u001b[39m1e-6\u001b[39;49m),\n\u001b[0;32m     15\u001b[0m         tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mEarlyStopping(monitor\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mval_loss\u001b[39;49m\u001b[39m'\u001b[39;49m, patience\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     16\u001b[0m     ]\n\u001b[0;32m     17\u001b[0m )\n\u001b[0;32m     19\u001b[0m \u001b[39mreturn\u001b[39;00m history\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras\\engine\\training.py:1607\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1596\u001b[0m \u001b[39mif\u001b[39;00m validation_split \u001b[39mand\u001b[39;00m validation_data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1597\u001b[0m     \u001b[39m# Create the validation data using the training data. Only supported\u001b[39;00m\n\u001b[0;32m   1598\u001b[0m     \u001b[39m# for `Tensor` and `NumPy` input.\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     (\n\u001b[0;32m   1600\u001b[0m         x,\n\u001b[0;32m   1601\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1604\u001b[0m         (x, y, sample_weight), validation_split\u001b[39m=\u001b[39mvalidation_split\n\u001b[0;32m   1605\u001b[0m     )\n\u001b[1;32m-> 1607\u001b[0m \u001b[39mif\u001b[39;00m validation_data:\n\u001b[0;32m   1608\u001b[0m     (\n\u001b[0;32m   1609\u001b[0m         val_x,\n\u001b[0;32m   1610\u001b[0m         val_y,\n\u001b[0;32m   1611\u001b[0m         val_sample_weight,\n\u001b[0;32m   1612\u001b[0m     ) \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39munpack_x_y_sample_weight(validation_data)\n\u001b[0;32m   1614\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy\u001b[39m.\u001b[39m_should_use_with_coordinator:\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "trained_model = train_yolov3_model(yolov3_model, trainDataSet, valDataSet, yolov3_loss, mean_iou)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
