{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Include all packages\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.layers import add, concatenate, BatchNormalization, LeakyReLU, ZeroPadding2D\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, MeanSquaredError\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  import zipfile\n",
    "\n",
    "# with zipfile.ZipFile('/content/drive/MyDrive/DL/FinalProject/signDatabasePublicFramesOnly.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('./DataSet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "if len(physical_devices) > 0:  # If you have at least one \"configured\" GPU, let's use it; otherwise, pass\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    print(\"Using GPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadDataSet(dataSetFolderPath: str):\n",
    "    images = []\n",
    "    newAnnotations = []\n",
    "    annotationsFilePath = dataSetFolderPath+\"/allAnnotations.csv\"\n",
    "    annotationsDataFrame = pd.read_csv(annotationsFilePath,sep=\";\")\n",
    "    width, height = 416, 416\n",
    "    for index, row in annotationsDataFrame[1:].iterrows():\n",
    "        image = cv2.imread(dataSetFolderPath+\"/\"+row[0])\n",
    "        # cv2.imshow(\"image\", image)\n",
    "        resizedImage  = cv2.resize(image, (width, height), interpolation=cv2.INTER_AREA)\n",
    "        # cv2.imshow(\"resized_img\", resized_img)\n",
    "        images.append(resizedImage)\n",
    "        x1,y1,x2,y2 = row[2],row[3],row[4],row[5]\n",
    "        x1, y1 = x1 / image.shape[1], y1 / image.shape[0]\n",
    "        x2, y2 = x2 / image.shape[1], y2 / image.shape[0]\n",
    "        newAnnotations.append([row[1], x1,y1,x2,y2])\n",
    "    uniqueSigns =  annotationsDataFrame['Annotation tag'].unique()\n",
    "    del annotationsDataFrame\n",
    "    X_train, X_val, y_train, y_val = train_test_split(images, newAnnotations, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Create TensorFlow Datasets\n",
    "    trainDataSet = tf.data.Dataset.from_tensor_slices((np.array(X_train), np.array(y_train)))\n",
    "    valDataSet = tf.data.Dataset.from_tensor_slices((np.array(X_val), np.array(y_val)))\n",
    "    return trainDataSet, valDataSet, uniqueSigns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _conv_block(x, num_filters, kernel_size, strides=1):\n",
    "    x = Conv2D(num_filters, kernel_size, strides=strides, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _residual_block(x, num_filters):\n",
    "    shortcut = x\n",
    "    x = _conv_block(x, num_filters // 2, 1)\n",
    "    x = _conv_block(x, num_filters, 3)\n",
    "    x = add([shortcut, x])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_darknet53(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = _conv_block(inputs, 32, 3)\n",
    "    x = _conv_block(x, 64, 3, strides=2)\n",
    "\n",
    "    for _ in range(1):\n",
    "        x = _residual_block(x, 64)\n",
    "\n",
    "    x = _conv_block(x, 128, 3, strides=2)\n",
    "\n",
    "    for _ in range(2):\n",
    "        x = _residual_block(x, 128)\n",
    "\n",
    "    x = _conv_block(x, 256, 3, strides=2)\n",
    "\n",
    "    for _ in range(8):\n",
    "        x = _residual_block(x, 256)\n",
    "\n",
    "    route1 = x\n",
    "    x = _conv_block(x, 512, 3, strides=2)\n",
    "\n",
    "    for _ in range(8):\n",
    "        x = _residual_block(x, 512)\n",
    "\n",
    "    route2 = x\n",
    "    x = _conv_block(x, 1024, 3, strides=2)\n",
    "\n",
    "    for _ in range(4):\n",
    "        x = _residual_block(x, 1024)\n",
    "\n",
    "    return Model(inputs, (route1, route2, x), name='darknet53')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _create_yolov3(input_shape, num_classes):\n",
    "    darknet = _create_darknet53(input_shape[:-1] + (3,))\n",
    "\n",
    "    x = darknet.output[2]\n",
    "    x = _conv_block(x, 512, 1)\n",
    "    x = _conv_block(x, 1024, 3)\n",
    "    x = _conv_block(x, 512, 1)\n",
    "    x = _conv_block(x, 1024, 3)\n",
    "    x = _conv_block(x, 512, 1)\n",
    "\n",
    "    y1 = _conv_block(x, 1024, 3)\n",
    "    y1 = Conv2D(3 * (num_classes + 5), 1, padding='same')(y1)\n",
    "    print(\"y1 shape:\", y1.shape)\n",
    "\n",
    "    x = _conv_block(x, 256, 1)\n",
    "    x = UpSampling2D(2)(x)\n",
    "    x = concatenate([x, darknet.output[1]])\n",
    "\n",
    "    x = _conv_block(x, 256, 1)\n",
    "    x = _conv_block(x, 512, 3)\n",
    "    x = _conv_block(x, 256, 1)\n",
    "    x = _conv_block(x, 512, 3)\n",
    "    x = _conv_block(x, 256, 1)\n",
    "\n",
    "    y2 = _conv_block(x, 512, 3)\n",
    "    y2 = Conv2D(3 * (num_classes + 5), 1, padding='same')(y2)\n",
    "    print(\"y2 shape:\", y2.shape)\n",
    "\n",
    "    x = _conv_block(x, 128, 1)\n",
    "    x = UpSampling2D(2)(x)\n",
    "    x = concatenate([x, darknet.output[0]])\n",
    "\n",
    "    x = _conv_block(x, 128, 1)\n",
    "    x = _conv_block(x, 256, 3)\n",
    "    x = _conv_block(x, 128, 1)\n",
    "    x = _conv_block(x, 256, 3)\n",
    "    x = _conv_block(x, 128, 1)\n",
    "\n",
    "    y3 = _conv_block(x, 256, 3)\n",
    "    y3 = Conv2D(3 * (num_classes + 5), 1, padding='same')(y3)\n",
    "    print(\"y3 shape:\", y3.shape)\n",
    "\n",
    "    return Model(darknet.input, (y1, y2, y3), name='yolov3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_yolov3_loss_and_metric(yolov3_model, num_classes, num_anchors):\n",
    "    # num_classes = 3  # Update this value according to the number of traffic sign classes in your dataset\n",
    "    # num_anchors = 3  # The number of anchor boxes used in YOLOv3 (e.g., 3 for tiny YOLOv3)\n",
    "\n",
    "    # Define the loss components\n",
    "    objectness_loss = BinaryCrossentropy()\n",
    "    class_loss = BinaryCrossentropy()\n",
    "    bbox_loss = MeanSquaredError()\n",
    "\n",
    "    # Define the metric for evaluation (mean Intersection over Union)\n",
    "    mean_iou = MeanIoU(num_classes=num_classes)\n",
    "\n",
    "    def yolov3_loss(y_true, y_pred):\n",
    "        # Extract the ground truth and predictions for objectness, class, and bbox\n",
    "        y_true_objectness, y_true_class, y_true_bbox = tf.split(y_true, [num_anchors, num_classes, 4], axis=-1)\n",
    "        y_pred_objectness, y_pred_class, y_pred_bbox = tf.split(y_pred, [num_anchors, num_classes, 4], axis=-1)\n",
    "\n",
    "        # Calculate the individual losses\n",
    "        objectness_loss_value = objectness_loss(y_true_objectness, y_pred_objectness)\n",
    "        class_loss_value = class_loss(y_true_class, y_pred_class)\n",
    "        bbox_loss_value = bbox_loss(y_true_bbox, y_pred_bbox)\n",
    "\n",
    "        # Combine the losses\n",
    "        total_loss = objectness_loss_value + class_loss_value + bbox_loss_value\n",
    "        return total_loss\n",
    "\n",
    "    return yolov3_loss, mean_iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_yolov3_model(yolov3_model, trainDataSet, valDataSet, loss_function, metric):\n",
    "    # Set up the loss and metric\n",
    "\n",
    "    # Compile the model with the loss function and metric\n",
    "    yolov3_model.compile(optimizer='adam', loss=loss_function, metrics=[metric])\n",
    "\n",
    "    # Train the model on the dataset\n",
    "    history = yolov3_model.fit(\n",
    "        trainDataSet.batch(32),\n",
    "        epochs=100,\n",
    "        validation_data=valDataSet.batch(32),\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.ModelCheckpoint('yolov3_best_weights.h5', save_best_only=True, monitor='val_loss'),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, min_lr=1e-6),\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataSet, valDataSet, uniqueSigns = LoadDataSet(\"./DataSet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_shape = (416, 416, 3)\n",
    "num_classes = len(uniqueSigns)  \n",
    "print(num_classes)\n",
    "# Create the YOLOv3 model\n",
    "yolov3_model = _create_yolov3(input_shape, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yolov3_model.compile(optimizer='adam', loss=yolov3_loss, metrics=[mean_iou])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(1,9):\n",
    "    try:\n",
    "        print(i)\n",
    "        num_anchors = i\n",
    "        yolov3_loss, mean_iou = setup_yolov3_loss_and_metric(yolov3_model, num_classes, num_anchors)\n",
    "\n",
    "        trained_model = train_yolov3_model(yolov3_model, trainDataSet, valDataSet, yolov3_loss, mean_iou)\n",
    "    except:\n",
    "        print(\"error\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
