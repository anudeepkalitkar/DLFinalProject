{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXK9HEutb2Nq",
        "outputId": "7657bc30-cfa7-4551-8ac1-203bff44e3e6"
      },
      "outputs": [],
      "source": [
        "!pip install yolov5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2paW5x1rcBV2",
        "outputId": "a370e98d-35dc-4ee0-f24b-687856280473"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbxYFmu8cCA6",
        "outputId": "3073d510-a3d6-4171-b47f-febabc05adb9"
      },
      "outputs": [],
      "source": [
        "!pip install -r yolov5/requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQdle6ECbu-5"
      },
      "outputs": [],
      "source": [
        "#Include all packages\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from yolov5.models.yolo import Model\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "# import tensorflow as tf\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from tensorflow.keras.models import Model, Sequential\n",
        "# from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
        "# from tensorflow.keras.layers import add, concatenate, BatchNormalization, LeakyReLU, ZeroPadding2D\n",
        "# from tensorflow.keras.losses import BinaryCrossentropy, MeanSquaredError\n",
        "# from tensorflow.keras.metrics import MeanIoU\n",
        "# import torch.optim as optim\n",
        "\n",
        "# import pandas as pd\n",
        "# from yolov5.models.yolo import Model\n",
        "# from yolov5.models.common import CSPDarknet53"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggf594ltbu-6",
        "outputId": "b638391f-7d18-4cbd-dd0c-82bb2697f332"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXAvhuVnbu-6"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/DL/FinalProject/signDatabasePublicFramesOnly.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('./DataSet')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OW8Sq5-Rbu-7",
        "outputId": "7564b186-6465-4a7a-cee3-a50b03e08a8a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iMxCddibu-7"
      },
      "outputs": [],
      "source": [
        "def LoadDataSet(dataSetFolderPath: str):\n",
        "    images = []\n",
        "    newAnnotations = []\n",
        "    annotationsFilePath = dataSetFolderPath+\"/allAnnotations.csv\"\n",
        "    annotationsDataFrame = pd.read_csv(annotationsFilePath,sep=\";\")\n",
        "    uniqueSigns =  annotationsDataFrame['Annotation tag'].unique().tolist()\n",
        "    width, height = 416, 416\n",
        "    for index, row in annotationsDataFrame[1:].iterrows():\n",
        "        image = cv2.imread(dataSetFolderPath+\"/\"+row[0])\n",
        "        # cv2.imshow(\"image\", image)\n",
        "        resizedImage  = cv2.resize(image, (width, height), interpolation=cv2.INTER_AREA)\n",
        "        # cv2.imshow(\"resized_img\", resized_img)\n",
        "        images.append(resizedImage)\n",
        "        x1,y1,x2,y2 = row[2],row[3],row[4],row[5]\n",
        "        x1, y1 = x1 / image.shape[1], y1 / image.shape[0]\n",
        "        x2, y2 = x2 / image.shape[1], y2 / image.shape[0]\n",
        "        newAnnotations.append([uniqueSigns.index(row[1]),x1,y1,x2,y2])\n",
        "\n",
        "    del annotationsDataFrame\n",
        "    X_train, X_val, y_train, y_val = train_test_split(images, newAnnotations, test_size=0.3, random_state=42)\n",
        "\n",
        "    return X_train, X_val, y_train, y_val , uniqueSigns\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68sCzcEAbu-7"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, transform=None):\n",
        "        self.data = data  # data should be a list of (input, label) pairs\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_data, label = self.data[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            input_data = self.transform(input_data)\n",
        "        input_data = torch.from_numpy(input_data).float()\n",
        "        label = torch.tensor(label).float()\n",
        "        return input_data, label\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owhzzQF61a0L"
      },
      "outputs": [],
      "source": [
        "# def targets_to_tensors(targets, num_anchors, grid_sizes, num_classes):\n",
        "#     batch_size = int(targets[:, 0].max()) + 1\n",
        "#     target_obj = []\n",
        "#     target_cls = []\n",
        "#     target_box = []\n",
        "\n",
        "#     for grid_size in grid_sizes:\n",
        "#         target_obj.append(torch.zeros((batch_size, num_anchors, grid_size, grid_size)))\n",
        "#         target_cls.append(torch.zeros((batch_size, num_anchors, grid_size, grid_size, num_classes)))\n",
        "#         target_box.append(torch.zeros((batch_size, num_anchors, grid_size, grid_size, 4)))\n",
        "\n",
        "#     for target in targets:\n",
        "#         # print(target)\n",
        "#         batch_index, cls, x_center, y_center, width, height = target.long()\n",
        "\n",
        "#         for i, grid_size in enumerate(grid_sizes):\n",
        "#             x_cell, y_cell = int(x_center * grid_size), int(y_center * grid_size)\n",
        "#             anchor = 0  # Assuming only one anchor per grid cell for simplicity\n",
        "\n",
        "#             target_obj[i][batch_index, anchor, y_cell, x_cell] = 1\n",
        "#             target_cls[i][batch_index, anchor, y_cell, x_cell, cls] = 1\n",
        "#             target_box[i][batch_index, anchor, y_cell, x_cell] = torch.tensor([x_center, y_center, width, height])\n",
        "\n",
        "#     return target_obj, target_cls, target_box\n",
        "\n",
        "def targets_to_tensors(targets, batch_size, num_anchors, grid_sizes, num_classes):\n",
        "    target_obj = []\n",
        "    target_cls = []\n",
        "    target_box = []\n",
        "    # batch_size = 32\n",
        "    for grid_size in grid_sizes:\n",
        "        target_obj.append(torch.zeros((batch_size, num_anchors, grid_size, grid_size, 1)))\n",
        "        target_cls.append(torch.zeros((batch_size, num_anchors, grid_size, grid_size, num_classes)))\n",
        "        target_box.append(torch.zeros((batch_size, num_anchors, grid_size, grid_size, 4)))\n",
        "    # current_batch_size = int(targets[:, 0].max()) + 1\n",
        "    # print(\"current_batch_size\",targets.size(0))\n",
        "    for target in targets:\n",
        "        batch_index, cls, x_center, y_center, width, height = target.long()\n",
        "\n",
        "        for i, grid_size in enumerate(grid_sizes):\n",
        "          \n",
        "          x_cell, y_cell = int(x_center * grid_size), int(y_center * grid_size)\n",
        "          anchor = 0\n",
        "          # if current_batch_size < batch_size:\n",
        "          try:\n",
        "\n",
        "              target_obj[i][batch_index, anchor, y_cell, x_cell, 0] = 1\n",
        "              target_cls[i][batch_index, anchor, y_cell, x_cell, cls] = 1\n",
        "              target_box[i][batch_index, anchor, y_cell, x_cell] = torch.tensor([x_center, y_center, width, height])\n",
        "          except Exception as e:\n",
        "            # print(e)\n",
        "            pass\n",
        "    return target_obj, target_cls, target_box\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCXFHrH5zfQx"
      },
      "outputs": [],
      "source": [
        "\n",
        "class YOLOv5Loss(nn.Module):\n",
        "    def __init__(self, num_classes, num_anchors=3):\n",
        "        super(YOLOv5Loss, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.num_anchors = num_anchors\n",
        "\n",
        "    # def forward(self, preds, targets):\n",
        "    #     obj_loss = torch.tensor(0.0, device=preds[0].device)\n",
        "    #     cls_loss = torch.tensor(0.0, device=preds[0].device)\n",
        "    #     box_loss = torch.tensor(0.0, device=preds[0].device)\n",
        "    #     # batch_size = int(targets[:, 0].max()) + 1\n",
        "        \n",
        "    #     grid_sizes = [pred.size(2) for pred in preds]\n",
        "    #     target_obj_list, target_cls_list, target_box_list = targets_to_tensors(targets, self.num_anchors, grid_sizes, self.num_classes)\n",
        "    #     for i, pred in enumerate(preds):\n",
        "            \n",
        "    #         pred_obj = pred[..., 4].sigmoid()\n",
        "    #         pred_cls = pred[..., 5:].sigmoid()\n",
        "    #         pred_box = pred[..., :4]\n",
        "\n",
        "    #         target_obj = target_obj_list[i].to(pred.device)\n",
        "    #         target_cls = target_cls_list[i].to(pred.device)\n",
        "    #         target_box = target_box_list[i].to(pred.device)\n",
        "  \n",
        "    #         obj_loss += nn.BCEWithLogitsLoss()(pred[..., 4], target_obj)\n",
        "    #         cls_loss += nn.BCEWithLogitsLoss()(pred[..., 5:], target_cls)\n",
        "    #         box_loss += nn.MSELoss()(pred_box, target_box)\n",
        "\n",
        "    #     total_loss = obj_loss + cls_loss + box_loss\n",
        "    #     return total_loss\n",
        "    def forward(self, preds, targets):\n",
        "        obj_loss = torch.tensor(0.0, device=preds[0].device)\n",
        "        cls_loss = torch.tensor(0.0, device=preds[0].device)\n",
        "        box_loss = torch.tensor(0.0, device=preds[0].device)\n",
        "        batch_size = preds[0].size(0)\n",
        "        # print(\"batch_size\", batch_size)\n",
        "        grid_sizes = [pred.size(2) for pred in preds]\n",
        "        target_obj_list, target_cls_list, target_box_list = targets_to_tensors(targets, batch_size, self.num_anchors, grid_sizes, self.num_classes)\n",
        "        for i, pred in enumerate(preds):\n",
        "            \n",
        "            pred_obj = pred[..., 4].sigmoid()\n",
        "            pred_cls = pred[..., 5:].sigmoid()\n",
        "            pred_box = pred[..., :4]\n",
        "\n",
        "            target_obj = target_obj_list[i].to(pred.device)\n",
        "            target_cls = target_cls_list[i].to(pred.device)\n",
        "            target_box = target_box_list[i].to(pred.device)\n",
        "\n",
        "            obj_loss += nn.BCEWithLogitsLoss()(pred[..., 4:5], target_obj)\n",
        "            cls_loss += nn.BCEWithLogitsLoss()(pred[..., 5:], target_cls)\n",
        "            box_loss += nn.MSELoss()(pred[..., :4], target_box)\n",
        "\n",
        "\n",
        "        total_loss = obj_loss + cls_loss + box_loss\n",
        "        return total_loss\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wInmTyvrbu-9"
      },
      "outputs": [],
      "source": [
        "\n",
        "def setup_yolov5_loss_and_metric(num_classes, num_anchors):\n",
        "    # Define the loss components\n",
        "    objectness_loss = nn.BCELoss()\n",
        "    class_loss = nn.BCELoss()\n",
        "    bbox_loss = nn.MSELoss()\n",
        "    mean_iou = MeanIoU(num_classes=num_classes)\n",
        "\n",
        "    def yolov5_loss(y_true, y_pred):\n",
        "        # Extract the ground truth and predictions for objectness, class, and bbox\n",
        "        y_true_objectness, y_true_class, y_true_bbox = torch.split(y_true, [num_anchors, num_classes, 4], dim=-1)\n",
        "        y_pred_objectness, y_pred_class, y_pred_bbox = torch.split(y_pred, [num_anchors, num_classes, 4], dim=-1)\n",
        "\n",
        "        # Calculate the individual losses\n",
        "        objectness_loss_value = objectness_loss(y_pred_objectness, y_true_objectness)\n",
        "        class_loss_value = class_loss(y_pred_class, y_true_class)\n",
        "        bbox_loss_value = bbox_loss(y_pred_bbox, y_true_bbox)\n",
        "\n",
        "        # Combine the losses\n",
        "        total_loss = objectness_loss_value + class_loss_value + bbox_loss_value\n",
        "        return total_loss\n",
        "\n",
        "    return yolov5_loss, mean_iou"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZJ8-pMgbu-9"
      },
      "outputs": [],
      "source": [
        "def _create_yolov5(input_shape, num_classes, version=\"s\"):\n",
        "    cfg = f\"yolov5/models/yolov5{version}.yaml\"\n",
        "    model = Model(cfg, ch=3, nc=num_classes)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z884-9l6bu--"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val, uniqueSigns = LoadDataSet(\"./DataSet\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-JllmrYktgE",
        "outputId": "e2a76148-1a6f-411e-a6e6-4464949a6f54"
      },
      "outputs": [],
      "source": [
        "trainDataSet = []  # List of (input, label) pairs for the training set\n",
        "valDataSet = []  # List of (input, label) pairs for the validation set\n",
        "for i in range(len(X_train)):\n",
        "    trainDataSet.append((X_train[i],[i%32] + y_train[i]) )\n",
        "\n",
        "for i in range(len(X_val)):\n",
        "    valDataSet.append((X_val[i],[i%32] +y_val[i]) )\n",
        "# Create the datasets\n",
        "trainDataSetset = CustomDataset(trainDataSet)\n",
        "valDataSetset = CustomDataset(valDataSet)\n",
        "\n",
        "# Create the data loaders\n",
        "trainDataSetloader = DataLoader(trainDataSetset, batch_size=32, shuffle=True, num_workers=4)\n",
        "valDataSetloader = DataLoader(valDataSetset, batch_size=32, shuffle=False, num_workers=4)\n",
        "input_shape = (416, 416, 3)\n",
        "num_classes = len(uniqueSigns)  \n",
        "print(num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJrRAHOrbu--",
        "outputId": "c2e27810-699b-470a-9b87-8eecfd110677"
      },
      "outputs": [],
      "source": [
        "yolov5_model = _create_yolov5(input_shape, num_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLRIKiDjbu--"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(yolov5_model.parameters(), lr=0.001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDLJ5fHybu--"
      },
      "outputs": [],
      "source": [
        "num_anchors = 3\n",
        "# yolov5_loss, mean_iou = setup_yolov5_loss_and_metric( num_classes, num_anchors)\n",
        "yolov5_loss = YOLOv5Loss(num_classes=num_classes)\n",
        "\n",
        "mean_iou = MeanIoU(num_classes=num_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaOqEToJbu-_",
        "outputId": "42e90c68-754c-4cdb-fc3b-01a2d77c3aa6"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "num_epochs = 100\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "yolov5_model = yolov5_model.to(device)\n",
        "yolov5_loss.to(device)\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    print('-' * 20)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for phase in ['train']:\n",
        "        if phase == 'train':\n",
        "            yolov5_model.train()  # Set model to training mode\n",
        "            data_loader = trainDataSetloader\n",
        "        else:\n",
        "            yolov5_model.eval()  # Set model to evaluate mode\n",
        "            data_loader = valDataSetloader\n",
        "        data_loaderLength = len(data_loader)\n",
        "        running_loss = 0.0\n",
        "        running_metric = 0.0\n",
        "\n",
        "        # Iterate over data.\n",
        "        k=0\n",
        "        for inputs, labels in data_loader:\n",
        "            k+=1\n",
        "            inputs = inputs.permute(0, 3, 1, 2)\n",
        "            inputs = inputs.to(device)\n",
        "            # labels = [torch.tensor(label).to(device) for label in labels]\n",
        "            # labels = torch.stack(labels).to(device)\n",
        "            # labels = torch.cat(labels, dim=0)\n",
        "            labels = labels.to(device)\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                outputs = yolov5_model(inputs)\n",
        "                # print(\"Outputs shapes:\")\n",
        "                # for output in outputs:\n",
        "                #     print(output.shape)\n",
        "                # print(\"Labels shapes:\")\n",
        "                # for label in labels:\n",
        "                #     print(label.shape)\n",
        "                loss = yolov5_loss(outputs, labels)\n",
        "                # metric_value = mean_iou(outputs, labels)\n",
        "\n",
        "                # Backward + optimize only if in training phase\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            if((k*100//data_loaderLength)%10==0):\n",
        "                print((k*100//data_loaderLength),end =\"%,\")\n",
        "\n",
        "            # running_metric += metric_value.item() * inputs.size(0)\n",
        "\n",
        "        epoch_loss = running_loss / data_loaderLength\n",
        "        # epoch_metric = running_metric / len(data_loader.dataset)\n",
        "        print()\n",
        "        print(f\"{phase} Loss: {epoch_loss:.4f}\")\n",
        "        print(f\"{phase} took {(time.time() - start_time):.1f} seconds\")\n",
        "\n",
        "    print()\n",
        "\n",
        "print(\"Training complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cXWXTGuEoGv"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Save the trained model\n",
        "torch.save(yolov5_model.state_dict(), 'trained_yolov5_model.pth')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
