{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Gi1JVb63nB1",
        "outputId": "4556ee59-cb00-491f-95c4-acb9962b7499"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5.git\n",
        "!pip install -r yolov5/requirements.txt\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQdle6ECbu-5"
      },
      "outputs": [],
      "source": [
        "# Include all packages\n",
        "import os\n",
        "import shutil\n",
        "import cv2\n",
        "from time import time\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from yolov5.models.yolo import Model\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pycocotools.coco import COCO\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "from yolov5.utils.datasets import LoadImagesAndLabels\n",
        "from yolov5.utils.general import check_requirements\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggf594ltbu-6"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    import zipfile\n",
        "    with zipfile.ZipFile('/content/drive/MyDrive/DL Project/DataSet.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('./')\n",
        "except:\n",
        "    print(\"Using Local Machine\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xd2tU8GB3nB3"
      },
      "outputs": [],
      "source": [
        "def ResizeImage(image: np.ndarray, x1: int, y1: int, x2: int, y2: int, newWidth: int, newHeight: int) -> tuple:\n",
        "    originalHeight, originalWidth = image.shape[:2]\n",
        "    # widthScale = newWidth / originalWidth\n",
        "    # heightScale = newHeight / originalHeight\n",
        "    # resizedImage = cv2.resize(\n",
        "    #     image, (newWidth, newHeight), interpolation=cv2.INTER_LINEAR)\n",
        "    # x1New, y1New = int(x1 * widthScale), int(y1 * heightScale)\n",
        "    # x2New, y2New = int(x2 * widthScale), int(y2 * heightScale)\n",
        "    scale = min(newWidth / originalWidth, newHeight / originalHeight)\n",
        "    resizedImage = cv2.resize(image, (round(originalWidth * scale), round(originalHeight * scale)), interpolation=cv2.INTER_LINEAR)\n",
        "    dx = round((newWidth - resizedImage.shape[1]) / 2)\n",
        "    dy = round((newHeight - resizedImage.shape[0]) / 2)\n",
        "    paddedImage = cv2.copyMakeBorder(resizedImage, dy, dy, dx, dx, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
        "    x1New, y1New = int(x1 * scale + dx), int(y1 * scale + dy)\n",
        "    x2New, y2New = int(x2 * scale + dx), int(y2 * scale + dy)\n",
        "    return paddedImage, x1New, y1New, x2New, y2New\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iMxCddibu-7"
      },
      "outputs": [],
      "source": [
        "def LoadDataSet(dataSetFolderPath: str) -> tuple:\n",
        "    images = []\n",
        "    annotations = []\n",
        "    annotationsFilePath = dataSetFolderPath+\"/allAnnotations.csv\"\n",
        "    annotationsDataFrame = pd.read_csv(annotationsFilePath, sep=\";\")\n",
        "    uniqueSigns = annotationsDataFrame['Annotation tag'].unique().tolist()\n",
        "    for index, row in annotationsDataFrame[1:].iterrows():\n",
        "        image = cv2.imread(dataSetFolderPath+\"/\"+row[0])\n",
        "        images.append(image)\n",
        "        annotations.append(\n",
        "            [row[2], row[3], row[4], row[5]])\n",
        "\n",
        "    del annotationsDataFrame\n",
        "\n",
        "    return images, annotations, len(uniqueSigns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87wkTQy53nB4"
      },
      "outputs": [],
      "source": [
        "def PreProcessDataSet(images: list, annotations: list, batchSize: int, resize: tuple) -> tuple:\n",
        "    resizedImages = []\n",
        "    newAnnotations = []\n",
        "    for i, image in enumerate(images):\n",
        "        [x1, y1, x2, y2] = annotations[i]\n",
        "        resizedImage, x1New, y1New, x2New, y2New = ResizeImage(\n",
        "            image, x1, y1, x2, y2, resize[0], resize[1])\n",
        "        resizedImages.append(resizedImage)\n",
        "        newAnnotations.append(\n",
        "            [x1New, y1New, x2New, y2New])\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        resizedImages, newAnnotations, test_size=0.3, random_state=42)\n",
        "\n",
        "    return X_train, X_val, y_train, y_val\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68sCzcEAbu-7"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, transform=None):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        inputData, label = self.data[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            inputData = self.transform(inputData)\n",
        "        inputData = torch.from_numpy(inputData).float()\n",
        "        label = torch.tensor(label).float()\n",
        "        return inputData, label\n",
        "\n",
        "def CreateDataLoaders(X_train, X_val, y_train, y_val, batchSize):\n",
        "    trainDataSet = []\n",
        "    valDataSet = []\n",
        "    for i in range(len(X_train)):\n",
        "        trainDataSet.append((X_train[i], y_train[i]))\n",
        "\n",
        "    for i in range(len(X_val)):\n",
        "        valDataSet.append((X_val[i], y_val[i]))\n",
        "\n",
        "    trainDataSet = CustomDataset(trainDataSet)\n",
        "    valDataSet = CustomDataset(valDataSet)\n",
        "    trainDataLoader = DataLoader(\n",
        "        trainDataSet, batch_size=batchSize, shuffle=True, num_workers=4)\n",
        "    valDataLoader = DataLoader(\n",
        "        valDataSet, batch_size=batchSize, shuffle=False, num_workers=4)\n",
        "\n",
        "    return trainDataLoader, valDataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owhzzQF61a0L"
      },
      "outputs": [],
      "source": [
        "def TargetstoTensors(targets, batch_size, numAnchors, gridSizes, numClasses):\n",
        "    targetObj = []\n",
        "    targetClass = []\n",
        "    targetBox = []\n",
        "    # batch_size = 32\n",
        "    for grid_size in gridSizes:\n",
        "        targetObj.append(torch.zeros(\n",
        "            (batch_size, numAnchors, grid_size, grid_size, 1)))\n",
        "        targetClass.append(torch.zeros(\n",
        "            (batch_size, numAnchors, grid_size, grid_size, numClasses)))\n",
        "        targetBox.append(torch.zeros(\n",
        "            (batch_size, numAnchors, grid_size, grid_size, 4)))\n",
        "    # current_batch_size = int(targets[:, 0].max()) + 1\n",
        "    # print(\"current_batch_size\",targets.size(0))\n",
        "    for target in targets:\n",
        "        batchIndex, cls, xCenter, yCenter, width, height = target.long()\n",
        "\n",
        "        for i, grid_size in enumerate(gridSizes):\n",
        "\n",
        "            x_cell, y_cell = int(\n",
        "                xCenter * grid_size), int(yCenter * grid_size)\n",
        "            anchor = 0\n",
        "            try:\n",
        "                targetObj[i][batchIndex, anchor, y_cell, x_cell, 0] = 1\n",
        "                targetClass[i][batchIndex, anchor, y_cell, x_cell, cls] = 1\n",
        "                targetBox[i][batchIndex, anchor, y_cell, x_cell] = torch.tensor(\n",
        "                    [xCenter, yCenter, width, height])\n",
        "            except Exception as e:\n",
        "                # print(e)\n",
        "                pass\n",
        "    return targetObj, targetClass, targetBox\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCXFHrH5zfQx"
      },
      "outputs": [],
      "source": [
        "class YOLOv5Loss(nn.Module):\n",
        "    def __init__(self, numClasses, numAnchors=3):\n",
        "        super(YOLOv5Loss, self).__init__()\n",
        "        self.numClasses = numClasses\n",
        "        self.numAnchors = numAnchors\n",
        "\n",
        "    def forward(self, preds, targets):\n",
        "        objectLoss = torch.tensor(0.0, device=preds[0].device)\n",
        "        classLoss = torch.tensor(0.0, device=preds[0].device)\n",
        "        boxLoss = torch.tensor(0.0, device=preds[0].device)\n",
        "        batch_size = preds[0].size(0)\n",
        "        gridSizes = [pred.size(2) for pred in preds]\n",
        "        targetObjList, targetClassList, targetBoxList = TargetstoTensors(\n",
        "            targets, batch_size, self.numAnchors, gridSizes, self.numClasses)\n",
        "        for i, pred in enumerate(preds):\n",
        "            # pred_obj = pred[..., 4].sigmoid()\n",
        "            # pred_cls = pred[..., 5:].sigmoid()\n",
        "            # pred_box = pred[..., :4]\n",
        "\n",
        "            targetObj = targetObjList[i].to(pred.device)\n",
        "            targetClass = targetClassList[i].to(pred.device)\n",
        "            targetBox = targetBoxList[i].to(pred.device)\n",
        "\n",
        "            objectLoss += nn.BCEWithLogitsLoss()(pred[..., 4:5], targetObj)\n",
        "            classLoss += nn.BCEWithLogitsLoss()(pred[..., 5:], targetClass)\n",
        "            boxLoss += nn.MSELoss()(pred[..., :4], targetBox)\n",
        "\n",
        "        totalLoss = objectLoss + classLoss + boxLoss\n",
        "        return totalLoss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZJ8-pMgbu-9"
      },
      "outputs": [],
      "source": [
        "def CreateYolov5Model(numClasses: int, version: str):\n",
        "    congfigFile = \"yolov5/models/yolov5{}.yaml\".format(version)\n",
        "    model = Model(congfigFile, ch=3, nc=numClasses)\n",
        "    model.load_state_dict(torch.load(\"yolov5{}.pt\".format(version))[\"model\"].state_dict(), strict=False)\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbVy1m6T3nB6"
      },
      "outputs": [],
      "source": [
        "def TrainModel(model, dataLoader, epochs, optimizer, lossFunction, device):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        print(\"Epoch {}/{}:\".format(epoch+1, epochs))\n",
        "        startTime = time()\n",
        "        runningLoss = 0\n",
        "        dataLoaderLen = len(dataLoader)\n",
        "        for i, (inputs, targets) in enumerate(dataLoader):\n",
        "            inputs = inputs.permute(0, 3, 1, 2)\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            with torch.set_grad_enabled(True):\n",
        "                outputs = model(inputs)\n",
        "                loss = lossFunction(outputs, targets)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            runningLoss += loss.item() * inputs.size(0)\n",
        "            if(((i*100)//dataLoaderLen) % 10 == 0):\n",
        "                print((i*100//dataLoaderLen), end=\"%,\")\n",
        "        endTime = time()\n",
        "        timeTaken = endTime-startTime\n",
        "        epochLoss = runningLoss / dataLoaderLen\n",
        "        print()\n",
        "        print(\"Training Loss: {:.4f}\".format(epochLoss))\n",
        "        print(\"Time taken: {}min, {}, secs\".format(timeTaken//60, timeTaken % 60))\n",
        "\n",
        "    print(\"Training complete.\")\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def EvaluateModel(model, dataLoader, device,  numClasses, conf_thres=0.5, iou_thres=0.5):\n",
        "    print(\"Evaluateing Model:\")\n",
        "    model.eval()\n",
        "    detections = []\n",
        "    labels = []\n",
        "    startTime = time()\n",
        "    dataLoaderLen = len(dataLoader)\n",
        "    conf_thres = torch.tensor(conf_thres)\n",
        "    conf_thres = conf_thres.to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for inputs, label in dataLoader:\n",
        "            inputs = inputs.permute(0, 3, 1, 2)\n",
        "            inputs = inputs.to(device)\n",
        "            label = label.to(device)\n",
        "            \n",
        "            output = model(inputs)\n",
        "            output = torchvision.ops.nms(output[0], conf_thres, iou_thres)\n",
        "            \n",
        "            detections.extend(output.cpu().numpy())\n",
        "            labels.extend(label.cpu().numpy())\n",
        "\n",
        "    coco_gt = COCO()\n",
        "    coco_gt.dataset['annotations'] = labels\n",
        "    coco_gt.createIndex()\n",
        "\n",
        "    coco_dt = coco_gt.loadRes(detections)\n",
        "    coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n",
        "    coco_eval.params.imgIds = list(range(len(labels)))\n",
        "    coco_eval.evaluate()\n",
        "    coco_eval.accumulate()\n",
        "    coco_eval.summarize()\n",
        "\n",
        "    return coco_eval.stats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4adeyZX3nB6"
      },
      "outputs": [],
      "source": [
        "batchSize = 32\n",
        "inputShape = (640, 640)\n",
        "epochs = 100\n",
        "numAnchors = 3\n",
        "yolo5Version = 'm'\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_imN2T83nB6",
        "outputId": "5abee8fb-3512-4773-dcf1-e85a92c30ad0"
      },
      "outputs": [],
      "source": [
        "print(\"Using {} device\".format(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Downloading Weights of yolo5 Verion \", yolo5Version)\n",
        "weightsURL = f\"https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5{}.pt\".format(yolo5Version)\n",
        "!wget {weightsURL}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z884-9l6bu--"
      },
      "outputs": [],
      "source": [
        "images, annotations, numClasses = LoadDataSet(\"./DataSet\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJAmoLT33nB6"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = PreProcessDataSet(\n",
        "    images, annotations, batchSize, inputShape)\n",
        "del images\n",
        "del annotations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IkU27xh3nB6"
      },
      "outputs": [],
      "source": [
        "trainDataLoader, valDataLoader = CreateDataLoaders(\n",
        "    X_train, X_val, y_train, y_val, batchSize)\n",
        "del X_train\n",
        "del y_train\n",
        "del X_val\n",
        "del y_val\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJrRAHOrbu--",
        "outputId": "3cd16fbb-87f6-4a41-8663-76ace9abf5f1"
      },
      "outputs": [],
      "source": [
        "yolov5Model = CreateYolov5Model(numClasses,yolo5Version)\n",
        "optimizer = optim.Adam(yolov5Model.parameters(), lr=0.001)\n",
        "yolov5LossFunction= YOLOv5Loss(numClasses=numClasses)\n",
        "yolov5Model = yolov5Model.to(device)\n",
        "yolov5LossFunction = yolov5LossFunction.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Atpoji13nB7",
        "outputId": "2b644c47-c751-4e4f-f561-5d9d6f549d94"
      },
      "outputs": [],
      "source": [
        "trainedModel = TrainModel(yolov5Model, trainDataLoader, epochs, optimizer, yolov5LossFunction, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGDk5r7d3nB7"
      },
      "outputs": [],
      "source": [
        "date = datetime.now()\n",
        "date = date.strftime(\"%m-%d-%H\")\n",
        "torch.save(trainedModel.state_dict(), 'yolov5Model' + date +'.pth')\n",
        "shutil.copy('/content/yolov5Model' + date +'.pth', '/content/drive/MyDrive/DL Project/Trained Models/yolov5Model' + date +'.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluationMetrics = EvaluateModel(yolov5Model, valDataLoader, device, numClasses)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"COCO Evaluation Metrics:\")\n",
        "print(\" Average Precision (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = {:.3f}\".format(evaluation_metrics[0]))\n",
        "print(\" Average Precision (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = {:.3f}\".format(evaluation_metrics[1]))\n",
        "print(\" Average Precision (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = {:.3f}\".format(evaluation_metrics[2]))\n",
        "print(\" Average Precision (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = {:.3f}\".format(evaluation_metrics[3]))\n",
        "print(\" Average Precision (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = {:.3f}\".format(evaluation_metrics[4]))\n",
        "print(\" Average Precision (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = {:.3f}\".format(evaluation_metrics[5]))\n",
        "print(\" Average Recall (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = {:.3f}\".format(evaluation_metrics[6]))\n",
        "print(\" Average Recall (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = {:.3f}\".format(evaluation_metrics[7]))\n",
        "print(\" Average Recall (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = {:.3f}\".format(evaluation_metrics[8]))\n",
        "print(\" Average Recall (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = {:.3f}\".format(evaluation_metrics[9]))\n",
        "print(\" Average Recall (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = {:.3f}\".format(evaluation_metrics[10]))\n",
        "print(\" Average Recall (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = {:.3f}\".format(evaluation_metrics[11]))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
