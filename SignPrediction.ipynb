{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5.git\n",
    "!pip install -r yolov5/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import cv2\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from yolov5.models.yolo import Model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, models, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import zipfile\n",
    "with zipfile.ZipFile('/content/drive/MyDrive/DL Project/TrafficSign DataSet.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('./')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResizeImage(image: np.ndarray, newWidth: int, newHeight: int) -> tuple:\n",
    "    resizedImage = cv2.resize(\n",
    "        image, (newWidth, newHeight), interpolation=cv2.INTER_LINEAR)\n",
    "    return resizedImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadDataSet(dataSetFolderPath: str) -> tuple:\n",
    "    images = []\n",
    "    annotations = []\n",
    "    annotationsFilePath = dataSetFolderPath+\"/tafficSignAnnotations.csv\"\n",
    "    annotationsDataFrame = pd.read_csv(annotationsFilePath, sep=\";\")\n",
    "    uniqueSigns = annotationsDataFrame['Catoregy'].unique().tolist()\n",
    "    for index, row in annotationsDataFrame[1:].iterrows():\n",
    "        image = cv2.imread(\".\"+row[1])\n",
    "        images.append(image)\n",
    "        annotations.append(uniqueSigns.index(row[0]))\n",
    "    del annotationsDataFrame\n",
    "    return images, annotations, len(uniqueSigns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PreProcessDataSet(images: list, annotations: list, batchSize: int, resize: tuple) -> tuple:\n",
    "    resizedImages = []\n",
    "    newAnnotations = []\n",
    "    for i, image in enumerate(images):\n",
    "        label = annotations[i]\n",
    "        resizedImage = ResizeImage(\n",
    "            image, resize[0], resize[1])\n",
    "        resizedImages.append(resizedImage)\n",
    "        newAnnotations.append(\n",
    "            [(i % batchSize), label])\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        resizedImages, newAnnotations, test_size=0.3, random_state=42)\n",
    "\n",
    "    return X_train, X_val, y_train, y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputData, label = self.data[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            inputData = self.transform(inputData)\n",
    "        inputData = torch.from_numpy(inputData).float()\n",
    "        label = torch.tensor(label).float()\n",
    "        return inputData, label\n",
    "\n",
    "def CreateDataLoaders(X_train, X_val, y_train, y_val, batchSize):\n",
    "    trainDataSet = []\n",
    "    valDataSet = []\n",
    "    for i in range(len(X_train)):\n",
    "        trainDataSet.append((X_train[i], y_train[i]))\n",
    "\n",
    "    for i in range(len(X_val)):\n",
    "        valDataSet.append((X_val[i], y_val[i]))\n",
    "\n",
    "    trainDataSet = CustomDataset(trainDataSet)\n",
    "    valDataSet = CustomDataset(valDataSet)\n",
    "    trainDataLoader = DataLoader(\n",
    "        trainDataSet, batch_size=batchSize, shuffle=True, num_workers=4)\n",
    "    valDataLoader = DataLoader(\n",
    "        valDataSet, batch_size=batchSize, shuffle=False, num_workers=4)\n",
    "\n",
    "    return trainDataLoader, valDataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainModel(model, dataLoader, epochs, optimizer, criterion, device):\n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch {}/{}:\".format(epoch+1, epochs))\n",
    "        startTime = time()\n",
    "        runningLoss = 0\n",
    "        dataLoaderLen = len(dataLoader)\n",
    "        runningAccuracy = 0\n",
    "\n",
    "        for i, (inputs, targets) in enumerate(dataLoader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with torch.set_grad_enabled(True):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            runningLoss += loss.item() * inputs.size(0)\n",
    "            runningAccuracy += torch.sum(preds == labels.data)\n",
    "            if(((i*100)//dataLoaderLen) % 10 == 0):\n",
    "                print((i*100//dataLoaderLen), end=\"%,\")\n",
    "        endTime = time()\n",
    "        timeTaken = endTime-startTime\n",
    "        epochLoss = runningLoss / dataLoaderLen\n",
    "        epochAccuracy = runningAccuracy.double() / dataLoaderLen\n",
    "        print()\n",
    "        print(\"Training Loss: {:.4f}\".format(epochLoss))\n",
    "        print(\"Training Accuracy: {:.4f}\".format(epochAccuracy))\n",
    "        print(\"Time taken: {}min, {}, secs\".format(timeTaken//60, timeTaken % 60))\n",
    "\n",
    "\n",
    "    print('Training complete')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 32\n",
    "inputShape = (416, 416)\n",
    "epochs = 100\n",
    "numAnchors = 3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Using {} device\".format(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, annotations, numClasses = LoadDataSet(\"./TrafficSign DataSet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = PreProcessDataSet(\n",
    "    images, annotations, batchSize, inputShape)\n",
    "del images\n",
    "del annotations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataLoader, valDataLoader = CreateDataLoaders(\n",
    "    X_train, X_val, y_train, y_val, batchSize)\n",
    "del X_train\n",
    "del y_train\n",
    "del X_val\n",
    "del y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, numClasses)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedModel = TrainModel(model, trainDataLoader, epochs, optimizer, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trainedModel.state_dict(), 'signPredictionV1.pth')\n",
    "trainedModel.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
